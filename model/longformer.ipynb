{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "longformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRzzIqFOY7X+4S5Nv45rb1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zumo09/Feedback-Prize/blob/main/model/longformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k178G_XkD0G"
      },
      "outputs": [],
      "source": [
        "from transformers import LongformerTokenizerFast, LongformerForTokenClassification, RobertaTokenizer, RobertaModel\n",
        "\n",
        "\n",
        "# THE TOKENS AND ATTENTION ARRAYS\n",
        "backbone =LongformerForTokenClassification.from_pretrained('../input/allenailongformerbase4096/longformer',num_labels = 15 )\n",
        "# THE TOKENS AND ATTENTION ARRAYS\n",
        "tokenizer = LongformerTokenizerFast.from_pretrained(\"../input/allenailongformerbase4096/longformer\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We need to define the classification style\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self,backbone):\n",
        "        super(Model, self).__init__()\n",
        "        self.backbone = backbone\n",
        "        self.linear_1 = torch.nn.Linear(X,128)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_2 = torch.nn.Linear(128, X)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "    \n",
        "    def forward(self, inp, att):\n",
        "        outs = backbone(inp,att)\n",
        "        outs = self.linear_1(outs.logits)\n",
        "        outs = self.relu(outs)\n",
        "        outs = self.linear_2(outs)\n",
        "        outs = self.softmax(outs)\n",
        "        return outs"
      ],
      "metadata": {
        "id": "5Y_DFuY-pjWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(backbone = backbone)\n",
        "#model.load_state_dict(torch.load(\"../input/model-weights-longformer-pytorch/model_weights7.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Z22c6oulpqD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaModel.from_pretrained('roberta-base')"
      ],
      "metadata": {
        "id": "UM2Z-8JJQ2B1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}