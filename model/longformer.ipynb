{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "longformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqbhdFJJajgRaR/VOWTqNT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zumo09/Feedback-Prize/blob/main/model/longformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "fVUuD-_Hisez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7k178G_XkD0G"
      },
      "outputs": [],
      "source": [
        "from transformers import LongformerTokenizerFast, LongformerConfig, LongformerModel, LEDConfig, LEDModel\n",
        "from torch.nn import Linear, Sequential, ReLU, Module\n",
        "import torch\n",
        "from transformers import logging\n",
        "\n",
        "logging.set_verbosity_warning()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.state_dict():\n",
        "  print(param)"
      ],
      "metadata": {
        "id": "3zioXBCEUAHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = LEDConfig.from_pretrained('allenai/led-base-16384', output_hidden_states=True)\n",
        "model = LEDModel(config)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "YKXQSQwHR-Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DETR(nn.Module):\n",
        "    \"\"\" This is the DETR module that performs object detection \"\"\"\n",
        "    def __init__(self, backbone, transformer, num_classes, num_queries, aux_loss=False):\n",
        "        \"\"\" Initializes the model.\n",
        "        Parameters:\n",
        "            backbone: torch module of the backbone to be used. See backbone.py\n",
        "            transformer: torch module of the transformer architecture. See transformer.py\n",
        "            num_classes: number of object classes\n",
        "            num_queries: number of object queries, ie detection slot. This is the maximal number of objects\n",
        "                         DETR can detect in a single image. For COCO, we recommend 100 queries.\n",
        "            aux_loss: True if auxiliary decoding losses (loss at each decoder layer) are to be used.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_queries = num_queries\n",
        "        self.transformer = transformer\n",
        "        hidden_dim = transformer.d_model\n",
        "        self.class_embed = nn.Linear(hidden_dim, num_classes + 1)\n",
        "        self.bbox_embed = MLP(hidden_dim, hidden_dim, 4, 3)\n",
        "        self.query_embed = nn.Embedding(num_queries, hidden_dim)\n",
        "        self.input_proj = nn.Conv2d(backbone.num_channels, hidden_dim, kernel_size=1)\n",
        "        self.backbone = backbone\n",
        "        self.aux_loss = aux_loss\n",
        "\n",
        "    def forward(self, samples: NestedTensor):\n",
        "        \"\"\" The forward expects a NestedTensor, which consists of:\n",
        "               - samples.tensor: batched images, of shape [batch_size x 3 x H x W]\n",
        "               - samples.mask: a binary mask of shape [batch_size x H x W], containing 1 on padded pixels\n",
        "            It returns a dict with the following elements:\n",
        "               - \"pred_logits\": the classification logits (including no-object) for all queries.\n",
        "                                Shape= [batch_size x num_queries x (num_classes + 1)]\n",
        "               - \"pred_boxes\": The normalized boxes coordinates for all queries, represented as\n",
        "                               (center_x, center_y, height, width). These values are normalized in [0, 1],\n",
        "                               relative to the size of each individual image (disregarding possible padding).\n",
        "                               See PostProcess for information on how to retrieve the unnormalized bounding box.\n",
        "               - \"aux_outputs\": Optional, only returned when auxilary losses are activated. It is a list of\n",
        "                                dictionnaries containing the two above keys for each decoder layer.\n",
        "        \"\"\"\n",
        "        if isinstance(samples, (list, torch.Tensor)):\n",
        "            samples = nested_tensor_from_tensor_list(samples)\n",
        "        features, pos = self.backbone(samples)\n",
        "\n",
        "        src, mask = features[-1].decompose()\n",
        "        assert mask is not None\n",
        "        hs = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1])[0]\n",
        "\n",
        "        outputs_class = self.class_embed(hs)\n",
        "        outputs_coord = self.bbox_embed(hs).sigmoid()\n",
        "        out = {'pred_logits': outputs_class[-1], 'pred_boxes': outputs_coord[-1]}\n",
        "        if self.aux_loss:\n",
        "            out['aux_outputs'] = self._set_aux_loss(outputs_class, outputs_coord)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "WYuXG3N05teB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LED Model fro encoder decoder part\n",
        "class LED(LEDModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(LED, self).__init__(config)\n",
        "        self.num_labels = config.num_labels + 1 # For no object class\n",
        "        self.longformer = LEDModel(config)\n",
        "        self.classifier = Linear(in_features = config['hidden_size'], out_features=self.num_labels) # it produces as output the class of the sequence\n",
        "        self.bb_estimator = Sequential(Linear(in_features=config['hidden_size'], out_features=sequence_length),\n",
        "                                       ReLU(),\n",
        "                                       Linear(in_features=sequence_length, out_features=d), # to define d\n",
        "                                       ReLU(),\n",
        "                                       Linear(in_features=d, out_features=2))# It produces as output the center and the lenght of the segment to classify\n",
        "        self.init_weights()\n",
        "    \n",
        "\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, global_attention_mask=None, \n",
        "                token_type_ids=None, position_ids=None, inputs_embeds=None, \n",
        "                labels=None):\n",
        "        \n",
        "        # create global attention on sequence, and a global attention token on the `s` token\n",
        "        # the equivalent of the CLS token on BERT models. This is taken care of by HuggingFace\n",
        "        # on the LongformerForSequenceClassification class\n",
        "        if global_attention_mask is None:\n",
        "            global_attention_mask = torch.zeros_like(input_ids)\n",
        "            global_attention_mask[:] = 1\n",
        "        \n",
        "        # pass arguments to longformer model\n",
        "        outputs = self.longformer(\n",
        "            input_ids = input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            global_attention_mask = global_attention_mask,\n",
        "            token_type_ids = token_type_ids,\n",
        "            position_ids = position_ids)\n",
        "        \n",
        "        # if specified the model can return a dict where each key corresponds to the output of a\n",
        "        # LongformerPooler output class. In this case we take the last hidden state of the sequence\n",
        "        # which will have the shape (batch_size, sequence_length, hidden_size). \n",
        "        sequence_output = outputs['last_hidden_state']\n",
        "        \n",
        "        # pass the hidden states through the classifier to obtain thee logits\n",
        "        #logits = self.classifier(sequence_output)\n",
        "        bb_center, bb_lenght = self.bb_estimator(sequence_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "        \n",
        "        return logits, bb\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "DAvMqYTZ0l_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedder(Module):\n",
        "  \n",
        "  def __init__(self, embedder, tokenizer, max_length):\n",
        "    super(Embedder, self).__init__()\n",
        "    self.max_length = max_length\n",
        "    self.embedder = embedder\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  \n",
        "  def forward(self, text):\n",
        "    token = self.tokenizer(text)\n",
        "    sequence_output, pooled_output = self.embedder(token)\n",
        "\n",
        "    return {'sequence_output': sequence_output, 'pooled_output': pooled_output}\n",
        "\n"
      ],
      "metadata": {
        "id": "lf3DbcWK57aJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = LongformerTokenizerFast.from_pretrained(\"allenai/longformer-base-4096\") \n",
        "config = LongformerConfig.from_pretrained('allenai/longformer-base-4096', output_hidden_states=True)\n",
        "model = LongformerModel(config).from_pretrained('allenai/longformer-base-4096')\n",
        "\n",
        "embedder = Embedder(model, tokenizer)"
      ],
      "metadata": {
        "id": "tT8wU8xb86I9",
        "outputId": "cca0cbb1-4786-44d0-885e-b5cd8fab8d4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('F4A4E65ADD95.txt') as f:\n",
        "  text = f.read()\n",
        "\n",
        "token = tokenizer(text)\n",
        "emb = model(token)"
      ],
      "metadata": {
        "id": "1xM3HPkw-c4X",
        "outputId": "dc5811f5-98fa-4f99-da08-5a70fa54341d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'size'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-daa6a693720b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FastText for embeddings words and SIF for documents embeddings\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "import fasttext\n",
        "\n",
        "model = fasttext.train_unsupervised('FC8DD899209B.txt', model='skipgram')\n",
        "def get_weighted_average(We, x, w):\n",
        "    \"\"\"\n",
        "    Compute the weighted average vectors\n",
        "    :param We: We[i,:] is the vector for word i\n",
        "    :param x: x[i, :] are the indices of the words in sentence i\n",
        "    :param w: w[i, :] are the weights for the words in sentence i\n",
        "    :return: emb[i, :] are the weighted average vector for sentence i\n",
        "    \"\"\"\n",
        "    n_samples = x.shape[0]\n",
        "    emb = np.zeros((n_samples, We.shape[1]))\n",
        "    for i in xrange(n_samples):\n",
        "        emb[i,:] = w[i,:].dot(We[x[i,:],:]) / np.count_nonzero(w[i,:])\n",
        "    return emb\n",
        "\n",
        "def compute_pc(X,npc=1):\n",
        "    \"\"\"\n",
        "    Compute the principal components. DO NOT MAKE THE DATA ZERO MEAN!\n",
        "    :param X: X[i,:] is a data point\n",
        "    :param npc: number of principal components to remove\n",
        "    :return: component_[i,:] is the i-th pc\n",
        "    \"\"\"\n",
        "    svd = TruncatedSVD(n_components=npc, n_iter=7, random_state=0)\n",
        "    svd.fit(X)\n",
        "    return svd.components_\n",
        "\n",
        "def remove_pc(X, npc=1):\n",
        "    \"\"\"\n",
        "    Remove the projection on the principal components\n",
        "    :param X: X[i,:] is a data point\n",
        "    :param npc: number of principal components to remove\n",
        "    :return: XX[i, :] is the data point after removing its projection\n",
        "    \"\"\"\n",
        "    pc = compute_pc(X, npc)\n",
        "    if npc==1:\n",
        "        XX = X - X.dot(pc.transpose()) * pc\n",
        "    else:\n",
        "        XX = X - X.dot(pc.transpose()).dot(pc)\n",
        "    return XX\n",
        "\n",
        "\n",
        "def SIF_embedding(We, x, w, params):\n",
        "    \"\"\"\n",
        "    Compute the scores between pairs of sentences using weighted average + removing the projection on the first principal component\n",
        "    :param We: We[i,:] is the vector for word i\n",
        "    :param x: x[i, :] are the indices of the words in the i-th sentence\n",
        "    :param w: w[i, :] are the weights for the words in the i-th sentence\n",
        "    :param params.rmpc: if >0, remove the projections of the sentence embeddings to their first principal component\n",
        "    :return: emb, emb[i, :] is the embedding for sentence i\n",
        "    \"\"\"\n",
        "    emb = get_weighted_average(We, x, w)\n",
        "    if  params.rmpc > 0:\n",
        "        emb = remove_pc(emb, params.rmpc)\n",
        "    return emb"
      ],
      "metadata": {
        "id": "rvOsB1av_W8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For summarization\n"
      ],
      "metadata": {
        "id": "Lcp2FPTgOr6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LongformerTokenizer, EncoderDecoderModel\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/longformer2roberta-cnn_dailymail-fp16\")\n",
        "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\") \n",
        "\n",
        "# Specify the article\n",
        "article = \"\"\"Germany (German: Deutschland, German pronunciation: [ˈdɔʏtʃlant]), officially the Federal Republic of Germany,[e] is a country at the intersection of Central and Western Europe. It is situated between the Baltic and North seas to the north, and the Alps to the south; covering an area of 357,022 square kilometres (137,847 sq mi), with a population of over 83 million within its 16 constituent states. It borders Denmark to the north, Poland and the Czech Republic to the east, Austria and Switzerland to the south, and France, Luxembourg, Belgium, and the Netherlands to the west. Germany is the second-most populous country in Europe after Russia, as well as the most populous member state of the European Union. Its capital and largest city is Berlin, and its financial centre is Frankfurt; the largest urban area is the Ruhr.Various Germanic tribes have inhabited the northern parts of modern Germany since classical antiquity. A region named Germania was documented before AD 100. In the 10th century, German territories formed a central part of the Holy Roman Empire. During the 16th century, northern German regions became the centre of the Protestant Reformation. Following the Napoleonic Wars and the dissolution of the Holy Roman Empire in 1806, the German Confederation was formed in 1815. In 1871, Germany became a nation-state when most of the German states unified into the Prussian-dominated German Empire. After World War I and the German Revolution of 1918–1919, the Empire was replaced by the semi-presidential Weimar Republic. The Nazi seizure of power in 1933 led to the establishment of a dictatorship, World War II, and the Holocaust. After the end of World War II in Europe and a period of Allied occupation, Germany was divided into the Federal Republic of Germany, generally known as West Germany, and the German Democratic Republic, East Germany. The Federal Republic of Germany was a founding member of the European Economic Community and the European Union, while the German Democratic Republic was a communist Eastern Bloc state and member of the Warsaw Pact. After the fall of communism, German reunification saw the former East German states join the Federal Republic of Germany on 3 October 1990—becoming a federal parliamentary republic led by a chancellor.Germany is a great power with a strong economy; it has the largest economy in Europe, the world's fourth-largest economy by nominal GDP, and the fifth-largest by PPP. As a global leader in several industrial, scientific and technological sectors, it is both the world's third-largest exporter and importer of goods. As a developed country, which ranks very high on the Human Development Index, it offers social security and a universal health care system, environmental protections, and a tuition-free university education. Germany is also a member of the United Nations, NATO, the G7, the G20, and the OECD. It also has the fourth-greatest number of UNESCO World Heritage Sites.\"\"\"\n",
        "\n",
        "# Tokenize and summarize\n",
        "input_ids = tokenizer(article, return_tensors=\"pt\").input_ids\n",
        "output_ids = model.generate(input_ids)\n",
        "\n",
        "# Get the summary from the output tokens\n",
        "summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Print summary\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "O5KRoUwcNt39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('F4A4E65ADD95.txt') as f:\n",
        "  article = f.read()\n",
        "\n",
        "#article = \"\"\"Germany (German: Deutschland, German pronunciation: [ˈdɔʏtʃlant]), officially the Federal Republic of Germany,[e] is a country at the intersection of Central and Western Europe. It is situated between the Baltic and North seas to the north, and the Alps to the south; covering an area of 357,022 square kilometres (137,847 sq mi), with a population of over 83 million within its 16 constituent states. It borders Denmark to the north, Poland and the Czech Republic to the east, Austria and Switzerland to the south, and France, Luxembourg, Belgium, and the Netherlands to the west. Germany is the second-most populous country in Europe after Russia, as well as the most populous member state of the European Union. Its capital and largest city is Berlin, and its financial centre is Frankfurt; the largest urban area is the Ruhr.Various Germanic tribes have inhabited the northern parts of modern Germany since classical antiquity. A region named Germania was documented before AD 100. In the 10th century, German territories formed a central part of the Holy Roman Empire. During the 16th century, northern German regions became the centre of the Protestant Reformation. Following the Napoleonic Wars and the dissolution of the Holy Roman Empire in 1806, the German Confederation was formed in 1815. In 1871, Germany became a nation-state when most of the German states unified into the Prussian-dominated German Empire. After World War I and the German Revolution of 1918–1919, the Empire was replaced by the semi-presidential Weimar Republic. The Nazi seizure of power in 1933 led to the establishment of a dictatorship, World War II, and the Holocaust. After the end of World War II in Europe and a period of Allied occupation, Germany was divided into the Federal Republic of Germany, generally known as West Germany, and the German Democratic Republic, East Germany. The Federal Republic of Germany was a founding member of the European Economic Community and the European Union, while the German Democratic Republic was a communist Eastern Bloc state and member of the Warsaw Pact. After the fall of communism, German reunification saw the former East German states join the Federal Republic of Germany on 3 October 1990—becoming a federal parliamentary republic led by a chancellor.Germany is a great power with a strong economy; it has the largest economy in Europe, the world's fourth-largest economy by nominal GDP, and the fifth-largest by PPP. As a global leader in several industrial, scientific and technological sectors, it is both the world's third-largest exporter and importer of goods. As a developed country, which ranks very high on the Human Development Index, it offers social security and a universal health care system, environmental protections, and a tuition-free university education. Germany is also a member of the United Nations, NATO, the G7, the G20, and the OECD. It also has the fourth-greatest number of UNESCO World Heritage Sites.\"\"\"\n",
        "\n",
        "# Tokenize and summarize\n",
        "input_ids = tokenizer(article, return_tensors=\"pt\").input_ids\n",
        "output_ids = model.generate(input_ids)\n",
        "\n",
        "# Get the summary from the output tokens\n",
        "summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Print summary\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3OtML11OTWX",
        "outputId": "8f817432-aed4-4b1d-d056-913e4ed4d3bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confiding in multiple people when looking for advice will give you a more reliable response.\n",
            "Asking multiple people about their experiences will give them a more detailed response. and give you more detailed responses.\n",
            "Ask multiple different people for their advice.\n",
            "People around you may have prior experience or opinions that can help you decide on a course of action.\n"
          ]
        }
      ]
    }
  ]
}